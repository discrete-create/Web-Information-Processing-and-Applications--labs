{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "830b8cdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 将构建流程封装成函数，便于脚本执行\n",
    "from pathlib import Path\n",
    "\n",
    "def run_part2_build(forward_file_path=\"normalized_tokens.json\", out_path=\"inverted_index.json\"):\n",
    "    if not Path(forward_file_path).exists():\n",
    "        raise FileNotFoundError(f\"未找到正排表文件: {forward_file_path}\")\n",
    "    index = ImprovedInvertedIndex()\n",
    "    ok = index.build_index_from_file(forward_file_path)\n",
    "    if not ok:\n",
    "        raise RuntimeError(\"构建失败：无法从JSON加载文档\")\n",
    "    index.print_index_statistics()\n",
    "    index.save_inverted_index(out_path)\n",
    "    return out_path\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64b4f9c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1) 位置索引：在倒排表中加入词项的位置信息\n",
    "from collections import defaultdict\n",
    "\n",
    "def build_positional_index_from_json(forward_file_path: str):\n",
    "    \"\"\"从正排表(文件->tokens列表)构建带位置信息的倒排索引。\n",
    "    返回: vocabulary(词->id), postings(termId -> [{doc, tf, pos:[...]}])\n",
    "    \"\"\"\n",
    "    import json\n",
    "    with open(forward_file_path, 'r', encoding='utf-8') as f:\n",
    "        token_dict = json.load(f)\n",
    "\n",
    "    # 词汇表\n",
    "    all_terms = sorted({t for tokens in token_dict.values() for t in tokens})\n",
    "    vocabulary = {t: i for i, t in enumerate(all_terms)}\n",
    "\n",
    "    # termId -> docId -> positions\n",
    "    positions_map = defaultdict(lambda: defaultdict(list))\n",
    "    for doc_id, tokens in token_dict.items():\n",
    "        for idx, tok in enumerate(tokens):\n",
    "            tid = vocabulary[tok]\n",
    "            positions_map[tid][doc_id].append(idx)\n",
    "\n",
    "    # 生成倒排结构（不加跳表，只演示位置信息）\n",
    "    postings = {}\n",
    "    for tid, doc2pos in positions_map.items():\n",
    "        items = []\n",
    "        for doc_id, pos_list in doc2pos.items():\n",
    "            items.append({\"doc\": doc_id, \"tf\": len(pos_list), \"skip\": -1, \"pos\": pos_list})\n",
    "        # 依据构建时的文档序保证顺序稳定\n",
    "        items.sort(key=lambda x: x[\"doc\"]) \n",
    "        postings[tid] = items\n",
    "\n",
    "    return vocabulary, postings\n",
    "\n",
    "\n",
    "def save_positional_index(vocabulary, postings, out_path: str):\n",
    "    import json\n",
    "    data = {\"vocabulary\": vocabulary, \"postings\": postings}\n",
    "    with open(out_path, 'w', encoding='utf-8') as f:\n",
    "        json.dump(data, f, ensure_ascii=False, indent=2)\n",
    "    print(f\"带位置信息的倒排索引已保存: {out_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb579b88",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2) 词典压缩：按块存储（Blocking, k=4）与前端编码（Front Coding）\n",
    "from typing import List, Tuple\n",
    "\n",
    "def encode_blocking(terms: List[str], k: int = 4) -> Tuple[bytes, List[int]]:\n",
    "    \"\"\"简化版按块存储编码。\n",
    "    输出: 编码后的字节序列、块起始偏移列表。\n",
    "    规则：\n",
    "    - 每个块的第一个词：写入 1字节长度 + 原词字节\n",
    "    - 块内其余词：写入 1字节长度 + 原词字节（演示用途，现实可结合前缀差分）\n",
    "    - 记录每块起始在字节流中的偏移\n",
    "    注：这里使用utf-8编码，长度以单字节保存，适用于英文小写示例。\n",
    "    \"\"\"\n",
    "    buf = bytearray()\n",
    "    offsets = []\n",
    "    for i, term in enumerate(terms):\n",
    "        if i % k == 0:\n",
    "            offsets.append(len(buf))\n",
    "        b = term.encode('utf-8')\n",
    "        l = len(b)\n",
    "        buf.append(l if l < 256 else 255)  # 简化：>255截断\n",
    "        buf.extend(b)\n",
    "    return bytes(buf), offsets\n",
    "\n",
    "\n",
    "def encode_front_coding(terms: List[str], k: int = 4) -> Tuple[bytes, List[int]]:\n",
    "    \"\"\"前端编码：每块记录第一个词原样，后续词存公共前缀长度+后缀。\n",
    "    约定：\n",
    "    - 块首：1字节长度 + 原词\n",
    "    - 其余：1字节公共前缀长度 + 1字节后缀长度 + 后缀字节\n",
    "    返回：编码字节、块偏移。\n",
    "    \"\"\"\n",
    "    buf = bytearray()\n",
    "    offsets = []\n",
    "    for i in range(0, len(terms)):\n",
    "        if i % k == 0:\n",
    "            offsets.append(len(buf))\n",
    "            head = terms[i].encode('utf-8')\n",
    "            buf.append(len(head) if len(head) < 256 else 255)\n",
    "            buf.extend(head)\n",
    "            base = terms[i]\n",
    "        else:\n",
    "            t = terms[i]\n",
    "            # 公共前缀\n",
    "            p = 0\n",
    "            while p < min(len(base), len(t)) and base[p] == t[p]:\n",
    "                p += 1\n",
    "            suffix = t[p:].encode('utf-8')\n",
    "            buf.append(p if p < 256 else 255)\n",
    "            buf.append(len(suffix) if len(suffix) < 256 else 255)\n",
    "            buf.extend(suffix)\n",
    "    return bytes(buf), offsets\n",
    "\n",
    "\n",
    "def measure_vocab_and_compression(vocabulary: dict, k: int = 4) -> dict:\n",
    "    terms_sorted = sorted(vocabulary.keys())\n",
    "    # 原始：直接串联+长度\n",
    "    raw_bytes = bytearray()\n",
    "    for t in terms_sorted:\n",
    "        b = t.encode('utf-8')\n",
    "        raw_bytes.append(len(b) if len(b) < 256 else 255)\n",
    "        raw_bytes.extend(b)\n",
    "    raw_size = len(raw_bytes)\n",
    "\n",
    "    blk_bytes, blk_offsets = encode_blocking(terms_sorted, k)\n",
    "    fc_bytes, fc_offsets = encode_front_coding(terms_sorted, k)\n",
    "\n",
    "    return {\n",
    "        \"vocab_size\": len(terms_sorted),\n",
    "        \"raw_size\": raw_size,\n",
    "        \"blocking\": {\"k\": k, \"bytes\": len(blk_bytes), \"blocks\": len(blk_offsets)},\n",
    "        \"front_coding\": {\"k\": k, \"bytes\": len(fc_bytes), \"blocks\": len(fc_offsets)}\n",
    "    }\n",
    "\n",
    "\n",
    "def save_compression_stats(stats: dict, out_path: str):\n",
    "    import json\n",
    "    with open(out_path, 'w', encoding='utf-8') as f:\n",
    "        json.dump(stats, f, indent=2, ensure_ascii=False)\n",
    "    print(f\"压缩统计已保存: {out_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "028d5ea6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3) 一键运行：生成 positional 索引与压缩统计\n",
    "forward = \"normalized_tokens.json\"\n",
    "pos_out = \"inverted_index_pos.json\"\n",
    "comp_out = \"compression_stats.json\"\n",
    "\n",
    "vocab, postings = build_positional_index_from_json(forward)\n",
    "save_positional_index(vocab, postings, pos_out)\n",
    "\n",
    "stats = measure_vocab_and_compression(vocab, k=4)\n",
    "save_compression_stats(stats, comp_out)\n",
    "\n",
    "print(\"完成：\\n - 带位置信息索引:\", pos_out, \"\\n - 压缩统计:\", comp_out)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f0f0bc7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "🚀 倒排索引构建系统 - 从JSON正排表文件构建\n",
      "============================================================\n",
      "\n",
      "📁 输入文件: normalized_tokens.json\n",
      "📖 从JSON文件加载正排表: normalized_tokens.json\n",
      "✅ 成功加载JSON格式，共 177065 个文档\n",
      "   文档ID示例: ['Group 1005141', 'Group 1014534', 'Group 1017036', 'Group 1021017', 'Group 1030709']\n",
      "   词项示例: ['subnat', 'purpose', 'discover', 'identify', 'plant']\n",
      "🔨 构建带跳表指针的倒排索引...\n",
      "  步骤1: 构建词汇表...\n",
      "    词汇表大小: 268574\n",
      "    词汇表示例: ['!!&nbsp;if', '!!limite', '!!synopsis', '!!welcome', '!).after', '!access', '!after', '!contact', '!either', '!for']\n",
      "  步骤2: 初始化文档排序系统...\n",
      "    文档数量: 177065\n",
      "  步骤3: 构建基础倒排列表...\n",
      "  步骤4: 对倒排列表排序...\n",
      "  步骤5: 添加跳表指针...\n",
      "✅ 构建完成：268574 个词项，327296 个跳表指针\n",
      "\n",
      "📊 索引统计信息:\n",
      "  词项数量: 268574\n",
      "  文档数量: 177065\n",
      "  倒排记录总数: 8062721\n",
      "  跳表指针数量: 327296\n",
      "  平均倒排列表长度: 30.02\n",
      "  词汇表示例: ['!!&nbsp;if', '!!limite', '!!synopsis', '!!welcome', '!).after', '!access', '!after', '!contact', '!either', '!for']\n",
      "\n",
      "========================================\n",
      "\n",
      "💾 保存倒排索引到: inverted_index.json\n",
      "✅ 倒排索引保存成功\n",
      "\n",
      "✅ 倒排索引构建流程完成!\n",
      "   输入: normalized_tokens.json (JSON正排表)\n",
      "   输出: inverted_index.json (JSON倒排索引)\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "import json\n",
    "from typing import List, Tuple, Dict, Any, Set\n",
    "\n",
    "class ImprovedInvertedIndex:\n",
    "    \"\"\"\n",
    "    改进的倒排索引类，直接从JSON文件读取已处理的正排表数据\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        # 词汇表：词项 -> 词项ID\n",
    "        self.vocabulary = {}\n",
    "        # 倒排列表：词项ID -> [(文档ID, 词频, 跳表指针), ...]\n",
    "        self.inverted_lists = {}\n",
    "        # 文档长度：文档ID -> 文档中的词项数量\n",
    "        self.doc_lengths = {}\n",
    "        # 文档ID到排序键的映射：文档ID -> 排序键（用于正确比较文档顺序）\n",
    "        self.doc_sort_keys = {}\n",
    "        # 排序键到文档ID的映射：排序键 -> 文档ID（用于反向查找）\n",
    "        self.sort_key_to_doc = {}\n",
    "        # 下一个可用的排序键\n",
    "        self.next_sort_key = 0\n",
    "    \n",
    "    def load_documents_from_json(self, file_path: str) -> Dict[str, List[str]]:\n",
    "        \"\"\"\n",
    "        从JSON文件加载正排表文档数据\n",
    "        \n",
    "        参数:\n",
    "            file_path: JSON正排表文件路径\n",
    "            \n",
    "        返回:\n",
    "            文档字典: {文档ID: [词项列表]}\n",
    "        \"\"\"\n",
    "        print(f\"📖 从JSON文件加载正排表: {file_path}\")\n",
    "        \n",
    "        try:\n",
    "            with open(file_path, 'r', encoding='utf-8') as f:\n",
    "                documents = json.load(f)\n",
    "            \n",
    "            # 验证数据格式\n",
    "            if not isinstance(documents, dict):\n",
    "                raise ValueError(\"JSON文件顶层结构必须是字典\")\n",
    "            \n",
    "            # 验证每个文档的词项列表\n",
    "            for doc_id, tokens in documents.items():\n",
    "                if not isinstance(tokens, list) or not all(isinstance(token, str) for token in tokens):\n",
    "                    raise ValueError(f\"文档 '{doc_id}' 的值必须是字符串列表\")\n",
    "            \n",
    "            print(f\"✅ 成功加载JSON格式，共 {len(documents)} 个文档\")\n",
    "            print(f\"   文档ID示例: {list(documents.keys())[:5]}\")\n",
    "            print(f\"   词项示例: {list(documents.values())[0][:5] if documents else '空'}\")\n",
    "            \n",
    "            return documents\n",
    "                \n",
    "        except Exception as e:\n",
    "            print(f\"❌ JSON文件加载失败: {e}\")\n",
    "            return {}\n",
    "    \n",
    "    def build_index_from_file(self, file_path: str):\n",
    "        \"\"\"\n",
    "        从JSON正排表文件构建倒排索引\n",
    "        \n",
    "        步骤:\n",
    "        1. 从文件加载正排表数据\n",
    "        2. 构建倒排索引\n",
    "        3. 添加跳表指针优化\n",
    "        \n",
    "        参数:\n",
    "            file_path: JSON正排表文件路径\n",
    "        \"\"\"\n",
    "        # 步骤1: 加载正排表数据\n",
    "        documents = self.load_documents_from_json(file_path)\n",
    "        if not documents:\n",
    "            print(\"❌ 无法加载文档数据，索引构建终止\")\n",
    "            return False\n",
    "        \n",
    "        # 步骤2: 构建倒排索引\n",
    "        self._build_index_with_skips(documents)\n",
    "        return True\n",
    "    \n",
    "    def _get_doc_sort_key(self, doc_id: str) -> int:\n",
    "        \"\"\"为文档ID生成排序键\"\"\"\n",
    "        if doc_id not in self.doc_sort_keys:\n",
    "            self.doc_sort_keys[doc_id] = self.next_sort_key\n",
    "            self.sort_key_to_doc[self.next_sort_key] = doc_id\n",
    "            self.next_sort_key += 1\n",
    "        return self.doc_sort_keys[doc_id]\n",
    "    \n",
    "    def _get_doc_id_from_sort_key(self, sort_key: int) -> str:\n",
    "        \"\"\"从排序键获取文档ID\"\"\"\n",
    "        return self.sort_key_to_doc.get(sort_key, \"\")\n",
    "    \n",
    "    def _compare_docs(self, doc1: str, doc2: str) -> int:\n",
    "        \"\"\"比较两个文档的顺序\"\"\"\n",
    "        key1 = self._get_doc_sort_key(doc1)\n",
    "        key2 = self._get_doc_sort_key(doc2)\n",
    "        if key1 < key2:\n",
    "            return -1\n",
    "        elif key1 > key2:\n",
    "            return 1\n",
    "        else:\n",
    "            return 0\n",
    "    \n",
    "    def _build_index_with_skips(self, token_dict: Dict[str, List[str]]):\n",
    "        \"\"\"构建带跳表指针的倒排索引\"\"\"\n",
    "        print(\"🔨 构建带跳表指针的倒排索引...\")\n",
    "        \n",
    "        # 步骤1: 构建词汇表\n",
    "        print(\"  步骤1: 构建词汇表...\")\n",
    "        all_tokens = set()\n",
    "        for doc_tokens in token_dict.values():\n",
    "            all_tokens.update(doc_tokens)\n",
    "        \n",
    "        sorted_tokens = sorted(all_tokens)\n",
    "        self.vocabulary = {token: idx for idx, token in enumerate(sorted_tokens)}\n",
    "        print(f\"    词汇表大小: {len(self.vocabulary)}\")\n",
    "        print(f\"    词汇表示例: {list(self.vocabulary.keys())[:10]}\")\n",
    "        \n",
    "        # 步骤2: 初始化文档排序系统\n",
    "        print(\"  步骤2: 初始化文档排序系统...\")\n",
    "        for doc_id in token_dict.keys():\n",
    "            self._get_doc_sort_key(doc_id)\n",
    "            self.doc_lengths[doc_id] = len(token_dict[doc_id])\n",
    "        print(f\"    文档数量: {len(token_dict)}\")\n",
    "        \n",
    "        # 步骤3: 构建基础倒排列表\n",
    "        print(\"  步骤3: 构建基础倒排列表...\")\n",
    "        for doc_id, tokens in token_dict.items():\n",
    "            term_freq = {}\n",
    "            for token in tokens:\n",
    "                term_id = self.vocabulary[token]\n",
    "                term_freq[term_id] = term_freq.get(term_id, 0) + 1\n",
    "            \n",
    "            for term_id, freq in term_freq.items():\n",
    "                if term_id not in self.inverted_lists:\n",
    "                    self.inverted_lists[term_id] = []\n",
    "                self.inverted_lists[term_id].append((doc_id, freq, -1))\n",
    "        \n",
    "        # 步骤4: 对每个倒排列表排序\n",
    "        print(\"  步骤4: 对倒排列表排序...\")\n",
    "        for term_id, postings in self.inverted_lists.items():\n",
    "            postings.sort(key=lambda x: self._get_doc_sort_key(x[0]))\n",
    "        \n",
    "        # 步骤5: 为长倒排列表添加跳表指针\n",
    "        print(\"  步骤5: 添加跳表指针...\")\n",
    "        skip_count = 0\n",
    "        for term_id, postings in self.inverted_lists.items():\n",
    "            if len(postings) >= 4:\n",
    "                skip_count += self._add_skip_pointers(term_id, postings)\n",
    "        \n",
    "        print(f\"✅ 构建完成：{len(self.inverted_lists)} 个词项，{skip_count} 个跳表指针\")\n",
    "    \n",
    "    def _add_skip_pointers(self, term_id: int, postings: List[Tuple]) -> int:\n",
    "        \"\"\"为倒排列表添加跳表指针\"\"\"\n",
    "        n = len(postings)\n",
    "        skip_interval = int(math.sqrt(n))\n",
    "        skip_count = 0\n",
    "        \n",
    "        for i in range(0, n, skip_interval):\n",
    "            if i + skip_interval < n:\n",
    "                doc_id, freq, _ = postings[i]\n",
    "                postings[i] = (doc_id, freq, i + skip_interval)\n",
    "                skip_count += 1\n",
    "        \n",
    "        return skip_count\n",
    "    \n",
    "    def search_with_skips_improved(self, query_terms: List[str]) -> Dict[str, Any]:\n",
    "        \"\"\"使用跳表指针的改进搜索算法\"\"\"\n",
    "        print(f\"\\n🔍 搜索查询: {query_terms}\")\n",
    "        \n",
    "        if not query_terms:\n",
    "            return {\"documents\": [], \"stats\": {\"message\": \"空查询\"}}\n",
    "        \n",
    "        term_ids = []\n",
    "        for term in query_terms:\n",
    "            if term in self.vocabulary:\n",
    "                term_ids.append(self.vocabulary[term])\n",
    "        \n",
    "        if not term_ids:\n",
    "            return {\"documents\": [], \"stats\": {\"message\": \"未找到匹配的词项\"}}\n",
    "        \n",
    "        print(f\"  找到 {len(term_ids)} 个匹配词项\")\n",
    "        \n",
    "        term_ids.sort(key=lambda tid: len(self.inverted_lists.get(tid, [])))\n",
    "        \n",
    "        first_term_id = term_ids[0]\n",
    "        result_docs = set(self._get_doc_ids(first_term_id))\n",
    "        print(f\"  初始列表长度: {len(result_docs)}\")\n",
    "        \n",
    "        for i, term_id in enumerate(term_ids[1:], 1):\n",
    "            current_docs = self._get_doc_ids(term_id)\n",
    "            print(f\"  与第{i+1}个列表求交集，长度: {len(current_docs)}\")\n",
    "            \n",
    "            result_docs = self._intersect_with_skips_improved(\n",
    "                list(result_docs), current_docs, term_id\n",
    "            )\n",
    "            print(f\"    交集后长度: {len(result_docs)}\")\n",
    "            \n",
    "            if not result_docs:\n",
    "                break\n",
    "        \n",
    "        sorted_docs = sorted(list(result_docs), key=lambda x: self._get_doc_sort_key(x))\n",
    "        \n",
    "        return {\n",
    "            \"documents\": sorted_docs,\n",
    "            \"stats\": {\n",
    "                \"query_terms\": query_terms,\n",
    "                \"matched_terms\": len(term_ids),\n",
    "                \"result_count\": len(result_docs),\n",
    "                \"searched_lists\": len(term_ids)\n",
    "            }\n",
    "        }\n",
    "    \n",
    "    def _get_doc_ids(self, term_id: int) -> List[str]:\n",
    "        \"\"\"获取词项对应的文档ID列表\"\"\"\n",
    "        if term_id not in self.inverted_lists:\n",
    "            return []\n",
    "        return [doc_id for doc_id, _, _ in self.inverted_lists[term_id]]\n",
    "    \n",
    "    def _intersect_with_skips_improved(self, list1: List[str], list2: List[str], term2_id: int) -> Set[str]:\n",
    "        \"\"\"使用跳表指针求两个文档列表的交集\"\"\"\n",
    "        result = set()\n",
    "        i = j = 0\n",
    "        postings2 = self.inverted_lists[term2_id]\n",
    "        \n",
    "        while i < len(list1) and j < len(list2):\n",
    "            doc1 = list1[i]\n",
    "            doc2 = list2[j]\n",
    "            \n",
    "            cmp_result = self._compare_docs(doc1, doc2)\n",
    "            \n",
    "            if cmp_result == 0:\n",
    "                result.add(doc1)\n",
    "                i += 1\n",
    "                j += 1\n",
    "            elif cmp_result < 0:\n",
    "                i += 1\n",
    "            else:\n",
    "                new_j = self._skip_forward(postings2, j, doc1)\n",
    "                if new_j > j:\n",
    "                    j = new_j\n",
    "                else:\n",
    "                    j += 1\n",
    "        \n",
    "        return result\n",
    "    \n",
    "    def _skip_forward(self, postings: List[Tuple], current_pos: int, target_doc: str) -> int:\n",
    "        \"\"\"使用跳表指针向前跳转\"\"\"\n",
    "        if current_pos >= len(postings):\n",
    "            return current_pos\n",
    "        \n",
    "        _, _, skip_ptr = postings[current_pos]\n",
    "        if skip_ptr != -1 and skip_ptr < len(postings):\n",
    "            skip_doc_id, _, _ = postings[skip_ptr]\n",
    "            \n",
    "            if self._compare_docs(skip_doc_id, target_doc) <= 0:\n",
    "                further_skip = self._skip_forward(postings, skip_ptr, target_doc)\n",
    "                if further_skip > skip_ptr:\n",
    "                    return further_skip\n",
    "                return skip_ptr\n",
    "        \n",
    "        return current_pos\n",
    "    \n",
    "    def save_inverted_index(self, output_path: str):\n",
    "        \"\"\"\n",
    "        将倒排索引保存到JSON文件\n",
    "        \n",
    "        参数:\n",
    "            output_path: 输出JSON文件路径\n",
    "        \"\"\"\n",
    "        print(f\"\\n💾 保存倒排索引到: {output_path}\")\n",
    "        \n",
    "        try:\n",
    "            with open(output_path, 'w', encoding='utf-8') as f:\n",
    "                f.write('{\\n')\n",
    "                f.write('  \"vocabulary\": ')\n",
    "                json.dump(self.vocabulary, f, indent=2, ensure_ascii=False, separators=(',', ': '))\n",
    "                f.write(',\\n')\n",
    "                \n",
    "                f.write('  \"inverted_lists\": {\\n')\n",
    "                term_ids = sorted(self.inverted_lists.keys(), key=int)\n",
    "                for i, term_id in enumerate(term_ids):\n",
    "                    f.write(f'    \"{term_id}\": [')\n",
    "                    postings = self.inverted_lists[term_id]\n",
    "                    for j, (doc_id, freq, skip_ptr) in enumerate(postings):\n",
    "                        if j > 0:\n",
    "                            f.write(', ')\n",
    "                        f.write(f'[\"{doc_id}\", {freq}, {skip_ptr}]')\n",
    "                    f.write(']')\n",
    "                    if i < len(term_ids) - 1:\n",
    "                        f.write(',')\n",
    "                    f.write('\\n')\n",
    "                f.write('  },\\n')\n",
    "                \n",
    "                f.write('  \"doc_lengths\": ')\n",
    "                json.dump(self.doc_lengths, f, indent=2, ensure_ascii=False, separators=(',', ': '))\n",
    "                f.write(',\\n')\n",
    "                \n",
    "                f.write('  \"doc_sort_keys\": ')\n",
    "                json.dump(self.doc_sort_keys, f, indent=2, ensure_ascii=False, separators=(',', ': '))\n",
    "                f.write(',\\n')\n",
    "                \n",
    "                f.write('  \"sort_key_to_doc\": ')\n",
    "                json.dump(self.sort_key_to_doc, f, indent=2, ensure_ascii=False, separators=(',', ': '))\n",
    "                f.write(',\\n')\n",
    "                \n",
    "                f.write(f'  \"next_sort_key\": {self.next_sort_key}\\n')\n",
    "                f.write('}\\n')\n",
    "                \n",
    "            print(\"✅ 倒排索引保存成功\")\n",
    "        except Exception as e:\n",
    "            print(f\"❌ 保存失败: {e}\")\n",
    "    \n",
    "    def print_index_statistics(self):\n",
    "        \"\"\"打印索引统计信息\"\"\"\n",
    "        print(\"\\n📊 索引统计信息:\")\n",
    "        print(f\"  词项数量: {len(self.vocabulary)}\")\n",
    "        print(f\"  文档数量: {len(self.doc_lengths)}\")\n",
    "        \n",
    "        total_postings = sum(len(postings) for postings in self.inverted_lists.values())\n",
    "        print(f\"  倒排记录总数: {total_postings}\")\n",
    "        \n",
    "        skip_count = self._count_skips()\n",
    "        print(f\"  跳表指针数量: {skip_count}\")\n",
    "        \n",
    "        if self.inverted_lists:\n",
    "            avg_length = total_postings / len(self.inverted_lists)\n",
    "            print(f\"  平均倒排列表长度: {avg_length:.2f}\")\n",
    "        \n",
    "        # 显示词汇表示例\n",
    "        if self.vocabulary:\n",
    "            sample_terms = list(self.vocabulary.keys())[:10]\n",
    "            print(f\"  词汇表示例: {sample_terms}\")\n",
    "    \n",
    "    def print_skip_structure(self, term: str):\n",
    "        \"\"\"打印词项的跳表结构\"\"\"\n",
    "        if term not in self.vocabulary:\n",
    "            print(f\"词项 '{term}' 不存在\")\n",
    "            return\n",
    "        \n",
    "        term_id = self.vocabulary[term]\n",
    "        if term_id not in self.inverted_lists:\n",
    "            print(f\"词项 '{term}' 无倒排列表\")\n",
    "            return\n",
    "        \n",
    "        postings = self.inverted_lists[term_id]\n",
    "        print(f\"\\n📋 词项 '{term}' 的跳表结构 (共{len(postings)}个文档):\")\n",
    "        \n",
    "        for i, (doc_id, freq, skip_ptr) in enumerate(postings):\n",
    "            skip_info = f\" → [{skip_ptr}]\" if skip_ptr != -1 else \"\"\n",
    "            sort_key = self._get_doc_sort_key(doc_id)\n",
    "            print(f\"  [{i:2d}] 文档: {doc_id:15s} (排序键:{sort_key:2d}), 频率: {freq}{skip_info}\")\n",
    "    \n",
    "    def _count_skips(self) -> int:\n",
    "        \"\"\"统计跳表指针数量\"\"\"\n",
    "        count = 0\n",
    "        for postings in self.inverted_lists.values():\n",
    "            for _, _, skip_ptr in postings:\n",
    "                if skip_ptr != -1:\n",
    "                    count += 1\n",
    "        return count\n",
    "\n",
    "\n",
    "def main():\n",
    "    \"\"\"\n",
    "    主函数：从JSON正排表文件构建倒排索引\n",
    "    \"\"\"\n",
    "    print(\"=\" * 60)\n",
    "    print(\"🚀 倒排索引构建系统 - 从JSON正排表文件构建\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    # 创建倒排索引实例\n",
    "    index = ImprovedInvertedIndex()\n",
    "    \n",
    "    # 文件路径配置 - 请根据实际情况修改这些路径\n",
    "    forward_file_path = \"normalized_tokens.json\"    # 输入的JSON正排表文件路径\n",
    "    inverted_index_path = \"inverted_index.json\" # 输出的倒排索引JSON文件路径\n",
    "    \n",
    "    # 从JSON文件构建倒排索引\n",
    "    print(f\"\\n📁 输入文件: {forward_file_path}\")\n",
    "    success = index.build_index_from_file(forward_file_path)\n",
    "    \n",
    "    if not success:\n",
    "        print(\"❌ 索引构建失败，程序退出\")\n",
    "        return\n",
    "    \n",
    "    # 打印统计信息\n",
    "    index.print_index_statistics()\n",
    "    \n",
    "    # 保存倒排索引到JSON文件\n",
    "    print(\"\\n\" + \"=\" * 40)\n",
    "    index.save_inverted_index(inverted_index_path)\n",
    "    \n",
    "    print(\"\\n✅ 倒排索引构建流程完成!\")\n",
    "    print(f\"   输入: {forward_file_path} (JSON正排表)\")\n",
    "    print(f\"   输出: {inverted_index_path} (JSON倒排索引)\")\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
